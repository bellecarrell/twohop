{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a0b9e0da-6b95-4eaf-b8c9-09e63ad14893",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using the legacy behaviour of the <class 'transformers.models.llama.tokenization_llama.LlamaTokenizer'>. This means that tokens that come after special tokens will not be properly handled. We recommend you to read the related pull request available at https://github.com/huggingface/transformers/pull/24565\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "42adea3c44e04b5abf5878383c5351c7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/594 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4bd7381c59584dc4853210dfc2a0e89c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors.index.json:   0%|          | 0.00/26.8k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c81c21f6c1d148db99015f382bc04816",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bc6e49028ab94b6785d97712740b4723",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00001-of-00002.safetensors:   0%|          | 0.00/9.98G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "91f39e84f325402694f03f92b514f965",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00002-of-00002.safetensors:   0%|          | 0.00/3.50G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "718af01979914988809ec7b1ccb89328",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d99ef2ffffbb47a89e494a232ce1e18a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/137 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Some parameters are on the meta device device because they were offloaded to the disk.\n"
     ]
    }
   ],
   "source": [
    "from queryexecutor import GPT2QueryExecutor, GPT3QueryExecutor, GPTJQueryExecutor, GPTNeoXQueryExecutor, \\\n",
    "    LlamaQueryExecutor\n",
    "\n",
    "query_executor = LlamaQueryExecutor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "40aa701f-be2f-48db-8086-9d8c9f7d6996",
   "metadata": {},
   "outputs": [],
   "source": [
    "from wikidata.utils import load_json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4386d7de-f3af-482b-ab45-da55a31bf9eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "one_hop_dataset = load_json('/Users/annabelle/workplace/RippleEdits/src/one_hop_from_two_hop_fom_top_ents_5_entities_0_facts_each.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d82d6a29-d428-4b44-8f1e-c2b2315e4c1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "query: {'prompt': 'The name of the father of Shahnaz Pahlavi is', 'answers': [{'value': 'Mohammad Reza Pahlavi', 'aliases': ['Mohammad Rezā Shāh Pahlavī', 'Shah of Iran Mohammad Reza Pahlavi', 'Shah of Iran Muḥammad Ri̤zā Shāh', 'Shah of Iran Moḥammad Rezā Shāh', 'Shah of Iran Mokhammed Reza Pakhlevi', 'Shah of Iran Muhammed Reza Pahlavi', 'Muḥammad, Shah of Iran Ri̤zā Shāh', 'Shah of Iran Mohammed Reza Pahlavi', 'Mohammed Reza, Shah of Iran Pahlavi', 'Mohammad Reza Shah Pahlavi', 'Mohammed Reza Pahlavi, Shah of Iran', 'Mohammed Reza Pahlavi', 'Mohammad-Reza Pahlavi', 'Mohammedreza pahlavi']}], 'query_type': 'regular', 'subject_id': 'Q256878', 'relation': 'FATHER', 'target_ids': ['Q128245'], 'phrase': None}\n",
      "model answer: The name of the father of Shahnaz Pahlavi is not known.\n",
      "\n",
      "## Career\n",
      "\n",
      "Shahnaz Pahlavi was a member of the Pahlavi dynasty. She was the daughter of Mohammad Reza Pahlavi, the last Shah of Iran, and his first wife, Princess Fawzia of Egypt\n",
      "query: {'prompt': 'The names of the siblings of Mohammad Reza Pahlavi are', 'answers': [{'value': 'Gholam Reza Pahlavi', 'aliases': []}], 'query_type': 'regular', 'subject_id': 'Q128245', 'relation': 'SIBLING', 'target_ids': ['Q5940835'], 'phrase': None}\n",
      "model answer: The names of the siblings of Mohammad Reza Pahlavi are:\n",
      "\n",
      "* Princess Shams Pahlavi (1932–2011)\n",
      "* Princess Fatemeh Pahlavi (1933–1987)\n",
      "* Princess Farahnaz Pahlavi (1938–2008)\n",
      "*\n",
      "total: 57 correct: 1 acc: 0.017543859649122806\n"
     ]
    }
   ],
   "source": [
    "total = len(one_hop_dataset.keys())\n",
    "correct = 0\n",
    "for i, one_hop_fact in enumerate(one_hop_dataset.keys()):\n",
    "    if i > 1:\n",
    "        break\n",
    "    q = Query.from_dict(one_hop_dataset[one_hop_fact])\n",
    "    res = query_executor.execute_query(q)\n",
    "    # Returns true if response in possible answers\n",
    "    if res:\n",
    "        correct +=1\n",
    "print(f'total: {total} correct: {correct} acc: {correct/total}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a9d79e23-e985-4d62-a948-5380fcff6e46",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<query.Query at 0x7fd8f07e7160>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from query import Query\n",
    "q = Query.from_dict(one_hop['Q256878_P22_Q128245'])\n",
    "for on"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
